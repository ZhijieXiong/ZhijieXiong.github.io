{
    "task": "ExerciseModeling",
    "papers": [
        {
            "model_name": "",
            "paper_title": "Auxiliary Task Guided Interactive Attention Model for Question Diﬃculty Prediction",
            "abstract": "Abstract. Online learning platforms conduct exams to evaluate the learners in a monotonous way, where the questions in the database may be classiﬁed into Bloom's Taxonomy as varying levels in complexity from basic knowledge to advanced evaluation. The questions asked in these exams to all learners are very much static. It becomes important to ask new questions with diﬀerent diﬃculty levels to each learner to provide a personalized learning experience. In this paper, we propose a multi-task method with an interactive attention mechanism, Qdiﬀ, for jointly predicting Bloom's Taxonomy and diﬃculty levels of academic questions. We model the interaction between the predicted bloom taxonomy representations and the input representations using an attention mechanism to aid in diﬃculty prediction. The proposed learning method would help learn representations that capture the relationship between Bloom's taxonomy and diﬃculty labels. The proposed multi-task method learns a good input representation by leveraging the relationship between the related tasks and can be used in similar settings where the tasks are related. The results demonstrate that the proposed method performs better than training only on diﬃculty prediction. However, Bloom's labels may not always be given for some datasets. Hence we soft label another dataset with a model ﬁne-tuned to predict Bloom's labels to demonstrate the applicability of our method to datasets with only diﬃculty labels.",
            "source": "AIED[C]",
            "year": "2022",
            "paper_file_name": "2022-AIED-Auxiliary Task Guided Interactive Attention Model for Question Difficulty Prediction.pdf"
        },
        {
            "model_name": "",
            "paper_title": "Question Difﬁculty Prediction for READING Problems in Standard Tests",
            "abstract": "Standard tests aim to evaluate the performance of examinees using different tests with consistent difﬁculties. Thus, a critical demand is to predict the difﬁculty of each test question before the test is conducted. Existing studies are usually based on the judgments of education experts (e.g., teachers), which may be subjective and labor intensive. In this paper, we propose a novel Test-aware Attention-based Convolutional Neural Network (TACNN) framework to automatically solve this Question Difﬁculty Prediction (QDP) task for READING problems (a typical problem style in English tests) in standard tests. Speciﬁcally, given the abundant historical test logs and text materials of questions, we ﬁrst design a CNN-based architecture to extract sentence representations for the questions. Then, we utilize an attention strategy to qualify the difﬁculty contribution of each sentence to questions. Considering the incomparability of question difﬁculties in different tests, we propose a test-dependent pairwise strategy for training TACNN and generating the difﬁculty prediction value. Extensive experiments on a real-world dataset not only show the effectiveness of TACNN, but also give interpretable insights to track the attention information for questions.",
            "source": "AAAI[C]",
            "year": "2017",
            "paper_file_name": "2017-AAAI-Question Difﬁculty Prediction for READING Problems in Standard Tests.pdf"
        },
        {
            "model_name": "QuesNet",
            "paper_title": "QuesNet: A Unified Representation for Heterogeneous Test Questions",
            "abstract": "Understanding learning materials (e.g. test questions) is a crucial\nissue in online learning systems, which can promote many ap-\nplications in education domain. Unfortunately, many supervised\napproaches suffer from the problem of scarce human labeled data,\nwhereas abundant unlabeled resources are highly underutilized. To\nalleviate this problem, an effective solution is to use pre-trained\nrepresentations for question understanding. However, existing pre-\ntraining methods in NLP area are infeasible to learn test question\nrepresentations due to several domain-specific characteristics in\neducation. First, questions usually comprise of heterogeneous data\nincluding content text, images and side information. Second, there\nexists both basic linguistic information as well as domain logic\nand knowledge. To this end, in this paper, we propose a novel\npre-training method, namely QuesNet, for comprehensively learn-\ning question representations. Specifically, we first design a unified\nframework to aggregate question information with its heteroge-\nneous inputs into a comprehensive vector. Then we propose a\ntwo-level hierarchical pre-training algorithm to learn better under-\nstanding of test questions in an unsupervised way. Here, a novel\nholed language model objective is developed to extract low-level\nlinguistic features, and a domain-oriented objective is proposed to\nlearn high-level logic and knowledge. Moreover, we show that Ques-\nNet has good capability of being fine-tuned in many question-based\ntasks. We conduct extensive experiments on large-scale real-world\nquestion data, where the experimental results clearly demonstrate\nthe effectiveness of QuesNet for question understanding as well as\nits superior applicability.",
            "source": "SIGKDD[C]",
            "year": "2019",
            "paper_file_name": "2019-SIGKDD-QuesNet@@A Unified Representation for Heterogeneous Test Questions.pdf"
        },
        {
            "model_name": "",
            "paper_title": "Finding Similar Exercises in Online Education Systems",
            "abstract": "In online education systems, finding similar exercises is a fundamental task of many applications, such as exercise retrieval and student modeling. Several approaches have been proposed for this task by simply using the specific textual content (e.g. the same knowledge concepts or the similar words) in exercises. However, the problem of how to systematically exploit the rich semantic information embedded in multiple heterogenous data (e.g. texts and images) to precisely retrieve similar exercises remains pretty much open. To this end, in this paper, we develop a novel Multimodal Attention-based Neural Network (MANN) framework for finding similar exercises in large-scale online education systems by learning a unified semantic representation from the heterogenous data. In MANN, given exercises with texts, images and knowledge concepts, we first apply a convolutional neural network to extract image representations and use an embedding layer for representing concepts. Then, we design an attention-based long short-term memory network to learn a unified semantic representation of each exercise in a multimodal way. Here, two attention strategies are proposed to capture the associations of texts and images, texts and knowledge concepts, respectively. Moreover, with a Similarity Attention, the similar parts in each exercise pair are also measured. Finally, we develop a pairwise training strategy for returning similar exercises. Extensive experimental results on real-world data clearly validate the effectiveness and the interpretation power of MANN.",
            "source": "SIGKDD[C]",
            "year": "2018",
            "paper_file_name": "2018-SIGKDD-Finding Similar Exercises in Online Education Systems.pdf"
        },
        {
            "model_name": "DisenQNet",
            "paper_title": "DisenQNet: Disentangled Representation Learning for Educational Questions",
            "abstract": "Learning informative representations for educational questions is a fundamental problem in online learning systems, which can promote many applications, e.g., difficulty estimation. Most solutions integrate all information of one question together following a supervised manner, where the representation results are unsatisfactory sometimes due to the following issues. First, they cannot ensure the presentation ability due to the scarcity of labeled data. Then, the label-dependent representation results have poor feasibility to be transferred. Moreover, aggregating all information into the unified may introduce some noises in applications since it cannot distinguish the diverse characteristics of questions. In this paper, we aim to learn the disentangled representations of questions. We propose a novel unsupervised model, namely DisenQNet, to divide one question into two parts, i.e., a concept representation that captures its explicit concept meaning and an individual representation that preserves its personal characteristics. We achieve this goal via mutual information estimation by proposing three self-supervised estimators in a large unlabeled question corpus. Then, we propose another enhanced model, DisenQNet+, that transfers the representation knowledge from unlabeled questions to labeled questions in specific applications by maximizing the mutual information between both. Extensive experiments on real-world datasets demonstrate that DisenQNet can generate effective and meaningful disentangled representations for questions, and furthermore, DisenQNet+ can improve the performance of different applications.",
            "source": "SIGKDD[C]",
            "year": "2021",
            "paper_file_name": "2021-SIGKDD-DisenQNet@@Disentangled Representation Learning for Educational Questions.pdf"
        },
        {
            "model_name": "",
            "paper_title": "Fine-Grained Similarity Measurement between Educational Videos and Exercises",
            "abstract": "In online learning systems, measuring the similarity between educational videos and exercises is a fundamental task with great application potentials. In this paper, we explore to measure the fine-grained similarity by leveraging multimodal information. The problem remains pretty much open due to several domain-specific characteristics. First, unlike general videos, educational videos contain not only graphics but also text and formulas, which have a fixed reading order. Both spatial and temporal information embedded in the frames should be modeled. Second, there are semantic associations between adjacent video segments. The semantic associations will affect the similarity and different exercises usually focus on the related context of different ranges. Third, the fine-grained labeled data for training the model is scarce and costly. To tackle the aforementioned challenges, we propose VENet to measure the similarity at both video-level and segment-level by just exploiting the video-level labeled data. Extensive experimental results on real-world data demonstrate the effectiveness of VENet.",
            "source": "MM[C]",
            "year": "2020",
            "paper_file_name": "2020-MM-Fine-Grained Similarity Measurement between Educational Videos and Exercises.pdf"
        },
        {
            "model_name": "",
            "paper_title": "Question Difficulty Prediction for Multiple Choice Problems in Medical Exams",
            "abstract": "In the ITS (Intelligent Tutoring System) services, personalized question recommendation is a critical function in which the key challenge is to predict the difficulty of each question. Given the difficulty of each question, ITS can allocate suitable questions for students with varied knowledge proficiency. Existing approaches mainly relied on expert labeling, which is both subjective and labor intensive. In this paper, we propose a Document enhanced Attention based neural Network(DAN) framework to predict the difficulty of multiple choice problems in medical exams. DAN consists of three major steps: (1) In addition to stem and options, DAN retrieves relevant medical documents to enrich the content of each question; (2) DAN breaks down the question's difficulty into two parts: the hardness for recalling the knowledge assessed by the question and the confusion degree to exclude distractors. For each part, DAN introduces corresponding attention layers to model it; (3) DAN combines two parts of difficulties together to predict the overall difficulty. We collect a real-world data set from one of the largest medical online education websites in China. And the experimental results demonstrate the effectiveness of the proposed framework.",
            "source": "CIKT[C]",
            "year": "2019",
            "paper_file_name": "2019-CIKT-Question Difficulty Prediction for Multiple Choice Problems in Medical Exams.pdf"
        },
        {
            "model_name": "",
            "paper_title": "Educational Question Mining At Scale: Prediction, Analysis and Personalization",
            "abstract": "Online education platforms enable teachers to share a large\nnumber of educational resources such as questions to form\nexercises and quizzes for students. With large volumes of\navailable questions, it is important to have an automated way\nto quantify their properties and intelligently select them for\nstudents, enabling effective and personalized learning expe-\nriences. In this work, we propose a framework for mining\ninsights from educational questions at scale. We utilize the\nstate-of-the-art Bayesian deep learning method, in particular\npartial variational auto-encoders (p-VAE), to analyze real stu-\ndents' answers to a large collection of questions. Based on\np-VAE, we propose two novel metrics that quantify question\nquality and difﬁculty, respectively, and a personalized strat-\negy to adaptively select questions for students. We apply our\nproposed framework to a real-world dataset with tens of thou-\nsands of questions and tens of millions of answers from an\nonline education platform. Our framework not only demon-\nstrates promising results in terms of statistical metrics but also\nobtains highly consistent results with domain experts' evalu-\nation.",
            "source": "AAAI[C]",
            "year": "2021",
            "paper_file_name": "2021-AAAI-Educational Question Mining At Scale.pdf"
        },
        {
            "model_name": "",
            "paper_title": "Reconciling Efficiency and Effectiveness of Exercise Retrieval: An Uncertainty Reduction Hashing Approach for Computerized Adaptive Testing",
            "abstract": "With the rapid development of intelligent education, Computerized Adaptive Testing(CAT) has garnered significant attention for its ability to tailor exercises to individual examinees. The adaptability of CAT is primarily achieved through the alternating optimization of two core components: the cognitive diagnosis model and the exercise selection module. However, existing CAT approaches, despite their remarkable achievements, often come at the expense of high time costs. Statistical-based approaches incur increased time overhead due to complex computations, while data-driven approaches further exacerbate time inefficiency because of the iterative processes in reinforcement learning, making it challenging to balance evaluation effectiveness and time efficiency. To this end, in this paper, we propose HashCAT, an efficient CAT approach based on learning to hash, aiming to balance efficiency and evaluation effectiveness. Our approach comprises two stages: the hash representation generation and the exercise selection. In the first stage, we design an information alignment module and a novel cognitive diagnosis function to model the interaction between examinees and exercises, generating hash representations with clear physical significance. In the second stage, we propose an uncertainty reduction-based algorithm that utilize information entropy to quantify the uncertainty in student ability estimation and selects exercises that most effectively reduce this uncertainty. Experimental results on four real-world datasets demonstrate that the proposed method significantly improves question selection efficiency while maintaining competitive evaluation performance. The code exists anonymously in https://github.com/sherklock/Intelligent-Education/tree/main/HashCAT-main.",
            "source": "SIGIR[C]",
            "year": "2025",
            "paper_file_name": "2025-SIGIR-Reconciling Efficiency and Effectiveness of Exercise Retrieval- An Uncertainty Reduction Hashing Approach for Computerized Adaptive Testing.pdf"
        }
    ]
}