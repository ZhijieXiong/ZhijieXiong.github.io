{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to PyEdmine\u2019s documentation!</p>"},{"location":"#introduction","title":"Introduction","text":"<p>PyEdmine is a library of algorithms for reproducing Knowledge Tracing, Cognitive Diagnosis, and Exercise Recommendation models.</p>"},{"location":"#implemented","title":"Implemented","text":""},{"location":"#built-in-data-preprocessing","title":"Built-in Data Preprocessing","text":"<ul> <li>Assist2009</li> <li>Assist2009-full</li> <li>Assist2012</li> <li>Assist2015</li> <li>Assist2017</li> <li>Edi2020-task1</li> <li>Edi2020-task34</li> <li>SLP-mat</li> <li>SLP-phy</li> <li>SLP-eng</li> <li>SLP-chi</li> <li>SLP-geo</li> <li>SLP-bio</li> <li>Moocradar-C[courseId]</li> <li>Statics2011</li> <li>Junyi2015</li> <li>Ednet-kt1</li> <li>Slepemapy-anatomy</li> <li>Poj</li> <li>Xes3g5m</li> </ul>"},{"location":"#built-in-models","title":"Built-in Models","text":""},{"location":"#knowledge-tracing","title":"Knowledge Tracing","text":"<ul> <li>DKT (Download the trained model)</li> <li>DKVMN (Download the trained model)</li> <li>SKVMN (Download the trained model)</li> <li>ATKT (Download the trained model)</li> <li>DKTForget (Download the trained model)</li> <li>qDKT (Download the trained model)</li> <li>AKT (Download the trained model)</li> <li>SimpleKT (Download the trained model)</li> <li>SparseKT (Download the trained model)</li> <li>DIMKT (Download the trained model)</li> <li>LPKT (Download the trained model)</li> <li>LBKT (Download the trained model)</li> <li>QIKT (Download the trained model)</li> <li>QDCKT (Download the trained model)</li> <li>MIKT (Download the trained model)</li> </ul>"},{"location":"#cognitive-diagnosis","title":"Cognitive Diagnosis","text":"<ul> <li>IRT (Download the trained model)</li> <li>MIRT (Download the trained model)</li> <li>DINA (Download the trained model)</li> <li>NCD (Download the trained model)</li> <li>RCD (Download the trained model)</li> <li>HyperCD (Download the trained model)</li> <li>HeirCDF </li> </ul>"},{"location":"#exercise-recommendation","title":"Exercise Recommendation","text":"<ul> <li>EB-CF </li> <li>UB-CF </li> <li>KG4EX (Download the trained model)</li> </ul>"},{"location":"doc/","title":"Document","text":""},{"location":"doc/#quick-start","title":"Quick Start","text":"<p>github</p>"},{"location":"doc/#data","title":"Data","text":""},{"location":"doc/#preporcessed-files","title":"Preporcessed Files","text":"<ul> <li><code>data.txt</code> - Data file in a unified format</li> <li><code>Q_table.npy</code> - Ndarray of shape (n_question, n_concept), where each row is a one-hot or multi-hot vector, indicating the correspondence between questions and concepts</li> <li><code>statics_preprocessed.json</code> - Statistics of the dataset</li> <li><code>[question|concept]_id_map.csv</code> - The correspondence between the original question/concept ID and the mapped question/concept ID (mapped to integers, starting from 0), as well as the meta information of the question and concept</li> </ul>"},{"location":"doc/#format-of-datatxt","title":"Format of <code>data.txt</code>","text":"<p>Example of Ednet-kt1 dataset</p> <pre><code>user_id,seq_len;question_seq,correctness_seq,time_seq,use_time_seq\n0\n76\n0,1,2,3,4,5,6,8,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,28,27,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,46,32,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,64,30,48,65\n1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0,0,1,0,1,0,1,0,1,1,1,1,1,1,1,0,0,1,1,1,1,0,1,0,1,1,1,1,0,1,0,0,0,1,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,1,0\n1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515916,1515917,1515917,1515917,1515917,1515917,1515917,1515917,1515917,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517126,1517184,1517184,1517184,1517184,1517185,1517185,1517185,1517185,1517185,1517185,1517185,1517185,1517185,1517185\n20,21,21,27,13,13,13,12,12,12,12,12,12,18,18,18,26,16,6,19,27,29,53,53,53,53,51,51,51,51,20,19,18,17,15,14,16,16,18,16,14,17,18,16,15,18,15,30,20,21,12,16,15,32,29,34,18,19,16,32,18,6,17,14,16,31,20,20,21,18,25,15,19,21,22,23\n1\n77\n70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,33,130,131,132,37,133,134,135,49,136,137,138,63,139,140,141,45\n0,0,0,0,1,0,0,1,1,0,1,1,0,1,1,1,0,1,0,1,1,1,0,0,1,1,0,0,0,1,0,0,1,1,0,1,1,1,1,1,0,0,1,0,0,1,1,1,0,0,1,1,0,0,0,1,0,1,0,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,0\n1562640,1562640,1562640,1562640,1562640,1562640,1562640,1564381,1564381,1564381,1564381,1564381,1564381,1564381,1564381,1564381,1564381,1565079,1565079,1565079,1565079,1565079,1565079,1565079,1565079,1565079,1565079,1565973,1565973,1565973,1565973,1565973,1565973,1565973,1565973,1565973,1565973,1566090,1566090,1566090,1566090,1566090,1566437,1566437,1566437,1566437,1566437,1568368,1568368,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568550,1568551,1568551,1568551,1568551,1568551,1568551,1568551,1568551,1568551,1568551\n29,21,27,10,7,4,16,36,33,33,19,34,42,9,21,24,4,37,160,24,8,5,21,32,16,24,19,9,14,5,19,4,15,10,11,9,5,9,15,11,7,38,15,20,21,9,15,18,15,18,20,10,24,5,20,13,10,12,9,15,20,13,14,19,9,9,14,14,21,10,14,13,21,16,18,17,23\n...\n</code></pre> <p>The first line is separated by a semicolon <code>;</code>. On the left is the user information contained in the dataset, and on the right is the information related to each interaction between the user and the question contained in the dataset.</p>"},{"location":"doc/#feature","title":"Feature","text":""},{"location":"doc/#concept-aggregation","title":"Concept Aggregation","text":"<p>The official code of some models can only run on a single-concept dataset (i.e., one question corresponds to only one concept), such as DKT. We designed an Embedding Layer that can automatically index the corresponding concept ids through the question id and return the aggregated (for example, average pooling) concept embedding corresponding to the question.</p>"},{"location":"doc/#mask-questions-or-concepts","title":"Mask Questions or Concepts","text":"<p>Use <code>Q</code> to represent the number of question in the dataset, and <code>C</code> to represent the number of concepts in the dataset.</p> <ul> <li> <p>Example 1: Use the question of the assist2009 dataset to train DKT.</p> <ol> <li>Create a folder <code>dataset_preprocessed/assist2009-no-concept</code> and save a unit diagonal matrix of size <code>Q*Q</code> in the folder and name it <code>Q_table.npy</code></li> <li>When training DKT, set the parameter <code>dataset_name</code> to <code>assist2009-no-concept</code></li> <li>Our code will automatically read information related to questions and concepts from the Q table</li> </ol> </li> <li> <p>Example 2: Only use the concept of the assist2009 dataset to train AKT.</p> <ol> <li>Create a folder <code>dataset_preprocessed/assist2009-no-question</code> and save a unit diagonal matrix of size <code>C*C</code> in the folder and name it <code>Q_table.npy</code></li> <li>When training AKT, set the parameter <code>dataset_name</code> to <code>assist2009-no-question</code></li> <li>Our code will automatically read information related to questions and concepts from the Q table</li> </ol> </li> </ul>"}]}